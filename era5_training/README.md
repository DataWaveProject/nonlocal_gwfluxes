# Running simple MWE inference

## Test data

To run `infer.py` and `infer.f90` you will need some test data and pre-trained model weights. You can use the following script
to get these:

```bash
bash get-model-and-data.sh
```

This will give you:

```
inputs/
└── 1x1_inputfeatures_u_v_theta_w_uw_vw_era5_training_data_hourly_2010_constant_mu_sigma_scaling01.nc
model-huggingface/
├── ann_cnn_1x1_global_global_era5_uvthetaw__train_epoch8.pt
├── ann_cnn_1x1_global_global_era5_uvthetaw__train_epoch94.pt
└── attnunet_era5_global_global_uvthetaw_mseloss_train_epoch119.pt
```

## Torchscript the models

You will need pytorch installed (which is already a prerequisite of nonlocalgw)

We also need to make some directories for storing our outputs:

```bash
mkdir -p outputs
mkdir -p test-data
```

First we would need torchscript'd models. These can be generated by running `inference.py` on this branch.

### Unet

```bash
python inference.py -M attention -d global -v global -f uvthetaw -e 119 -m 1 -s 1 -t era5 -i inputs/ -c model-huggingface/ -o outputs/ --script
```

This will generate some test data and a torchscripted model, to be used by `infer.f90` and `infer.py` later on.

```
nlgw_unet_gpu_scripted.pt
test-data/
├── unet-input.nc
└── unet-predict.nc
```

### Ann

```bash
python inference.py -M ann -d global -v global -f uvthetaw -e 8 -m 1 -s 1 -t era5 -i inputs/ -c model-huggingface/ -o outputs/ --script
```

This will generate some test data and a torchscripted model, to be used by `infer.f90` and `infer.py` later on.

```
nlgw_ann_gpu_scripted.pt
test-data/
├── ann-cnn-input.nc
└── ann-cnn-predict.nc
```

## Test scripted model (Python)

### Unet

To test the newly generate torchscript models, use the following command:

```bash
python infer.py -M attention -t test-data/ -s .
```

### Ann

```bash
python infer.py -M ann -t test-data/ -s .
```

## Test scripted model (Fortran)

### Unet

To test the newly generate torchscript models, use the following command:

```bash
bash compile-and-run.sh intel
```

This will compile `infer.f90` into `infer.exe`. This requires having cuda installed on your system. It also requires `ftorch` to
be installed. For instruction on how to install `ftorch` please see
[here](https://github.com/Cambridge-ICCS/FTorch?tab=readme-ov-file#installation).
